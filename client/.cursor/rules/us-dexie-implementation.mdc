---
description: Comprehensive implementation plan for refactoring US rate deck uploads to use Dexie storage
globs: 
alwaysApply: false
---

# Simplified US Rate Deck Dexie Implementation

## Overview
This document outlines a simplified approach to refactor the US rate deck uploads to use Dexie.js directly for local storage, eliminating the complex storage service abstraction layers.

## Current Issues

1. Over-engineered storage abstraction with multiple strategy patterns
2. Unnecessary complexity with conditional logic for different storage types
3. Indirect access to Dexie through multiple layers
4. No session cleanup for IndexedDB on page unload

## Simplified Implementation

### 1. Direct Dexie Integration in USService

**File**: `client/src/services/us.service.ts`

```typescript
import { type USStandardizedData, type InvalidUsRow } from '@/types/domains/us-types';
import { DBName } from '@/types/app-types';
import { useUsStore } from '@/stores/us-store';
import Papa from 'papaparse';
import useDexieDB from '@/composables/useDexieDB'; // Direct import of Dexie composable
import { useLergStore } from '@/stores/lerg-store';
import { COUNTRY_CODES } from '@/types/constants/country-codes';

export class USService {
  private store = useUsStore();

  constructor() {
    console.log('Initializing simplified US service');
  }

  // Process file and store directly in Dexie
  async processFile(
    file: File,
    columnMapping: Record<string, number>,
    startLine: number,
    indeterminateDefinition?: string
  ): Promise<{ fileName: string; records: USStandardizedData[] }> {
    const tableName = file.name.toLowerCase().replace('.csv', '');
    const { storeInDexieDB } = useDexieDB();
    
    // Clear any existing invalid rows for this file
    this.store.clearInvalidRowsForFile(file.name);

    return new Promise((resolve, reject) => {
      Papa.parse(file, {
        header: false,
        skipEmptyLines: true,
        complete: async (results: { data: string[][] }) => {
          try {
            // Skip to user-specified start line
            const dataRows = results.data.slice(startLine - 1);
            const validRecords: USStandardizedData[] = [];

            dataRows.forEach((row, index) => {
              // Extract values based on column mapping
              let npanxx = '';
              let npa = '';
              let nxx = '';

              // Handle NPANXX extraction - either directly or from NPA and NXX
              if (columnMapping.npanxx >= 0) {
                npanxx = row[columnMapping.npanxx]?.trim() || '';

                // Handle 7-digit NPANXX with leading "1"
                if (npanxx.length === 7 && npanxx.startsWith('1')) {
                  npanxx = npanxx.substring(1); // Remove leading "1"
                }

                // If we have NPANXX but not NPA/NXX, extract them
                if (npanxx.length === 6) {
                  npa = npanxx.substring(0, 3);
                  nxx = npanxx.substring(3, 6);
                }
                // Handle abnormal NPANXX values
                else if (npanxx) {
                  if (npanxx.length >= 3) {
                    npa = npanxx.substring(0, Math.min(3, npanxx.length));
                    nxx = npanxx.length > 3 ? npanxx.substring(3) : '';
                  }
                }
              } else if (columnMapping.npa >= 0 && columnMapping.nxx >= 0) {
                npa = row[columnMapping.npa]?.trim() || '';
                nxx = row[columnMapping.nxx]?.trim() || '';

                // Special handling for NPA with country code prefix ("1")
                if (npa.startsWith('1') && npa.length === 4) {
                  npa = npa.substring(1); // Remove leading "1"
                }

                npanxx = npa + nxx;
              }

              // Extract rate values
              const interRateStr =
                columnMapping.interstate >= 0 ? row[columnMapping.interstate] : '';
              const intraRateStr =
                columnMapping.intrastate >= 0 ? row[columnMapping.intrastate] : '';
              const indetermRateStr =
                columnMapping.indeterminate >= 0 ? row[columnMapping.indeterminate] : '';

              // Parse rates
              const interRate = parseFloat(interRateStr);
              const intraRate = parseFloat(intraRateStr);
              let indetermRate = parseFloat(indetermRateStr);

              // Handle indeterminate rate based on user selection
              if (isNaN(indetermRate) && indeterminateDefinition) {
                indetermRate = indeterminateDefinition === 'interstate' ? interRate : intraRate;
              }

              // Validate the data
              if (
                !npanxx ||
                npanxx.length !== 6 ||
                isNaN(interRate) ||
                isNaN(intraRate) ||
                isNaN(indetermRate)
              ) {
                const reason = !npanxx
                  ? 'NPANXX is empty'
                  : npanxx.length !== 6
                  ? `NPANXX length (${npanxx.length}) is not 6 digits`
                  : isNaN(interRate)
                  ? 'Invalid interstate rate'
                  : isNaN(intraRate)
                  ? 'Invalid intrastate rate'
                  : 'Invalid indeterminate rate';

                const invalidRow: InvalidUsRow = {
                  rowIndex: startLine + index,
                  npanxx,
                  npa,
                  nxx,
                  interRate: isNaN(interRate) ? interRateStr : interRate,
                  intraRate: isNaN(intraRate) ? intraRateStr : intraRate,
                  indetermRate: isNaN(indetermRate) ? indetermRateStr : indetermRate,
                  reason,
                };
                this.store.addInvalidRow(file.name, invalidRow);
              } else {
                validRecords.push({
                  npanxx,
                  npa,
                  nxx,
                  interRate,
                  intraRate,
                  indetermRate,
                });
              }
            });

            // Store directly in Dexie - no storage strategy conditional logic
            if (validRecords.length > 0) {
              await storeInDexieDB(validRecords, DBName.US, tableName);
              console.log(`[USService] Stored ${validRecords.length} records in Dexie for table: ${tableName}`);
            }

            this.store.addFileUploaded(file.name, tableName);

            // Determine component ID for file stats
            let componentId = '';
            if (this.store.getFileNameByComponent('us1') === file.name) {
              componentId = 'us1';
            } else if (this.store.getFileNameByComponent('us2') === file.name) {
              componentId = 'us2';
            } else {
              componentId = this.store.getFileNameByComponent('us1') ? 'us2' : 'us1';
            }

            // Calculate and store file stats
            await this.calculateFileStats(componentId, file.name);

            resolve({ fileName: file.name, records: validRecords });
          } catch (error) {
            reject(error);
          }
        },
        error: (error) => reject(new Error(`Failed to process CSV: ${error.message}`)),
      });
    });
  }

  // Get data directly from Dexie
  async getData(tableName: string): Promise<USStandardizedData[]> {
    try {
      const { loadFromDexieDB } = useDexieDB();
      const data = await loadFromDexieDB<USStandardizedData>(DBName.US, tableName);
      console.log(`[USService] Retrieved ${data.length} records from Dexie table: ${tableName}`);
      return data;
    } catch (error) {
      console.error(`Failed to get data from table ${tableName}:`, error);
      throw error;
    }
  }

  // Calculate file statistics
  async calculateFileStats(componentId: string, fileName: string): Promise<void> {
    try {
      const tableName = fileName.toLowerCase().replace('.csv', '');
      const data = await this.getData(tableName);

      if (!data || data.length === 0) return;

      // Calculate stats
      const totalCodes = data.length;

      // Calculate unique NPAs (area codes)
      const uniqueNPAs = new Set(data.map((item) => item.npa)).size;

      // Calculate unique percentage - for US, we use NPA uniqueness
      const uniquePercentage = ((uniqueNPAs / totalCodes) * 100).toFixed(2);

      // Calculate US NPA coverage using LERG data
      const lergStore = useLergStore();
      const totalUSNPAs = lergStore.getTotalUSNPAs;

      // Create a set of all NPAs from the file
      const allFileNPAs = new Set(data.map((item) => item.npa));

      // Count how many valid US NPAs are in our file (those that exist in LERG data)
      let validUSNPAsInFile = 0;

      // Get all US NPAs from LERG data
      const lergUSNPAs = new Set<string>();
      Object.entries(lergStore.stateNPAs)
        .filter(([code]) => (!COUNTRY_CODES[code] && code !== 'CA') || code === 'US')
        .forEach(([_, npas]) => {
          npas.forEach((npa) => {
            lergUSNPAs.add(npa);
            // Count if this NPA is also in our file
            if (allFileNPAs.has(npa)) {
              validUSNPAsInFile++;
            }
          });
        });

      // Calculate coverage based on valid US NPAs found in the file against total US NPAs
      const usNPACoveragePercentage =
        totalUSNPAs > 0 ? ((validUSNPAsInFile / totalUSNPAs) * 100).toFixed(2) : '0.00';

      // Calculate average rates
      const avgInterRate = data.reduce((sum, item) => sum + item.interRate, 0) / totalCodes;
      const avgIntraRate = data.reduce((sum, item) => sum + item.intraRate, 0) / totalCodes;
      const avgIndetermRate = data.reduce((sum, item) => sum + item.indetermRate, 0) / totalCodes;

      // Format rates to 4 decimal places
      const formattedAvgInterRate = parseFloat(avgInterRate.toFixed(4));
      const formattedAvgIntraRate = parseFloat(avgIntraRate.toFixed(4));
      const formattedAvgIndetermRate = parseFloat(avgIndetermRate.toFixed(4));

      // Update store
      this.store.setFileStats(componentId, {
        totalCodes,
        totalDestinations: uniqueNPAs,
        uniqueDestinationsPercentage: parseFloat(uniquePercentage),
        usNPACoveragePercentage: parseFloat(usNPACoveragePercentage),
        avgInterRate: formattedAvgInterRate,
        avgIntraRate: formattedAvgIntraRate,
        avgIndetermRate: formattedAvgIndetermRate,
      });
    } catch (error) {
      console.error('Error calculating file stats:', error);
    }
  }

  // Remove a table directly from Dexie
  async removeTable(tableName: string): Promise<void> {
    try {
      // Find the component ID associated with this table
      const fileName = tableName + '.csv';
      let componentId = '';

      if (this.store.getFileNameByComponent('us1') === fileName) {
        componentId = 'us1';
      } else if (this.store.getFileNameByComponent('us2') === fileName) {
        componentId = 'us2';
      }

      if (componentId) {
        // Clear file stats for this component
        this.store.clearFileStats(componentId);
      }

      // Use DexieDB directly
      const { getDB } = useDexieDB();
      const db = await getDB(DBName.US);
      
      if (db.hasStore(tableName)) {
        await db.deleteStore(tableName);
        console.log(`Table ${tableName} removed successfully from Dexie`);
      }
    } catch (error) {
      console.error(`Failed to remove table ${tableName}:`, error);
      throw error;
    }
  }

  // Clear all US data
  async clearData(): Promise<void> {
    try {
      const { deleteDatabase } = useDexieDB();
      await deleteDatabase(DBName.US);
      console.log('[USService] Cleared all Dexie data for US');
      
      // Reset the file tracking in the store
      this.store.resetFiles();
    } catch (error) {
      console.error('Failed to clear US data:', error);
      throw error;
    }
  }

  // Get record count for a table
  async getRecordCount(tableName: string): Promise<number> {
    try {
      const { getDB } = useDexieDB();
      const db = await getDB(DBName.US);
      
      if (db.hasStore(tableName)) {
        const count = await db.table(tableName).count();
        console.log(`[USService] Count for Dexie table ${tableName}: ${count}`);
        return count;
      }
      return 0;
    } catch (error) {
      console.error(`Failed to get record count for table ${tableName}:`, error);
      return 0;
    }
  }

  // List all tables and their record counts
  async listTables(): Promise<Record<string, number>> {
    try {
      // Get all tables and their counts directly from Dexie
      const { getDB } = useDexieDB();
      const db = await getDB(DBName.US);

      const result: Record<string, number> = {};
      for (const table of db.tables) {
        const count = await table.count();
        result[table.name] = count;
      }

      console.log(`[USService] Listed ${Object.keys(result).length} Dexie tables`);
      return result;
    } catch (error) {
      console.error('Failed to list tables:', error);
      return {};
    }
  }
}
```

### 2. Simplify Sample Data Loading for US

**File**: `client/src/utils/load-sample-data.ts`

```typescript
export async function loadSampleDecks(dbNames: DBNameType[]): Promise<void> {
  try {
    console.log('Starting sample deck loading for:', dbNames);
    
    // ... other code ...

    if (dbNames.includes(DBName.US)) {
      const usService = new USService();
      
      // Load US-Test1.csv data
      const usTestFile = 'US-Test1.csv';
      const usTestResponse = await fetch(`/src/data/sample/${usTestFile}`);
      const usTestBlob = new File([await usTestResponse.blob()], usTestFile);

      // Column mapping structure for USService
      const columnMapping = {
        npanxx: 0,          // Index of NPANXX column
        interstate: 1,      // Index of interstate rate column
        intrastate: 2,      // Index of intrastate rate column
        indeterminate: 3,   // Index of indeterminate rate column
        npa: -1,            // Not used if we have npanxx directly
        nxx: -1,            // Not used if we have npanxx directly
      };

      await usService.processFile(usTestBlob, columnMapping, 1);
      console.log('US sample data loaded successfully');
    }
    
    // ... other code ...
    
  } catch (error) {
    console.error('Error loading sample data:', error);
  }
}
```

### 3. Update Dashboard to List US Tables Directly

**File**: `client/src/pages/DashBoard.vue`

Update the `getIndexedDbTables` function to use the Dexie API directly:

```typescript
/**
 * Get IndexedDB tables using services - correctly check if databases exist
 */
async function getIndexedDbTables(): Promise<DatabaseTable[]> {
  console.log('Starting getIndexedDbTables');
  const tables: DatabaseTable[] = [];

  try {
    // For AZ: Use the Dexie API directly
    try {
      const { getDB } = useDexieDB();
      const azDb = await getDB(DBName.AZ);
      let totalAzRecords = 0;
      
      for (const table of azDb.tables) {
        const count = await table.count();
        totalAzRecords += count;
      }

      if (totalAzRecords > 0) {
        tables.push({
          name: DBName.AZ,
          count: totalAzRecords,
          storage: 'indexeddb' as const,
        });
      }
    } catch (error) {
      console.warn('Error checking AZ IndexedDB:', error);
    }

    // For US: Same direct approach
    try {
      const { getDB } = useDexieDB();
      const usDb = await getDB(DBName.US);
      let totalUsRecords = 0;
      
      for (const table of usDb.tables) {
        const count = await table.count();
        totalUsRecords += count;
      }

      if (totalUsRecords > 0) {
        tables.push({
          name: DBName.US,
          count: totalUsRecords,
          storage: 'indexeddb' as const,
        });
      }
    } catch (error) {
      console.warn('Error checking US IndexedDB:', error);
    }
    
    // ... other databases ...

  } catch (error) {
    console.error('Error in getIndexedDbTables:', error);
  }

  return tables;
}
```

## Implementation Steps

1. Update the `us.service.ts` file to use Dexie directly
2. Remove the storage service abstraction for US data
3. Update all references to the US service to use the new API
4. Update the US store to remove in-memory storage methods that are no longer needed
5. Update sample data loading to use the new API
6. Test the implementation with both sample and real data

## Benefits

1. Simplified architecture with direct database access
2. Improved performance by removing unnecessary abstraction layers
3. Better developer experience with clearer code paths
4. Consistent implementation between AZ and US services
5. Reduced code duplication and maintenance burden 